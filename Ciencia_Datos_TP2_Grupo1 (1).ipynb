{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5809a-107c-4197-b516-907bda964b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARTE I: FAMILIARIZANDNOS CON LA EPH Y LIMPIEZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427e099-b276-4613-9897-93d025c1ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "\n",
    "EPH2025 = pd.read_excel(r\"C:\\Users\\Usuario\\Downloads\\usu_individual_T125.xlsx\")\n",
    "\n",
    "EPH2005 = pd.read_stata(r\"C:\\Users\\Usuario\\Downloads\\Individual_t105.dta\")\n",
    "\n",
    "print(EPH2025.head())\n",
    "print(EPH2005.head())\n",
    "\n",
    "#Vamos a ver por cada región cuántos datos hay para poder elegir\n",
    "\n",
    "# 2025\n",
    "conteo_2025 = EPH2025['REGION'].value_counts()\n",
    "print(\"2025\",conteo_2025)\n",
    "\n",
    "# 2005\n",
    "conteo_2005 = EPH2005['region'].value_counts()\n",
    "print(\"2005\",conteo_2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a2ab8-a99b-4f8c-a819-39dec740e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db482d-1891-4b40-9d88-691b7dc041a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como nombraron distinto a las regiones en los dos años, vemos como se llaman así filtramos bien\n",
    "print(EPH2025['REGION'].unique())\n",
    "#está como 43\n",
    "\n",
    "# Lo mismo para 2005\n",
    "print(EPH2005['region'].unique())\n",
    "#está como Pampeana\n",
    "\n",
    "#nos aseguramos que estén las dos en minúsculas para poder unir las bases\n",
    "EPH2025.columns = EPH2025.columns.str.lower()\n",
    "EPH2005.columns = EPH2005.columns.str.lower()\n",
    "\n",
    "#nos quedamos solo con pampeana\n",
    "# Filtrar Región Pampeana en 2005\n",
    "EPH2005_pampeana = EPH2005[EPH2005['region'] == 'Pampeana'].copy()\n",
    "\n",
    "# Filtrar Región Pampeana en 2025 (código 43)\n",
    "EPH2025_pampeana = EPH2025[EPH2025['region'] == 43].copy()\n",
    "\n",
    "# Agregar columna 'anio' para diferenciar\n",
    "EPH2005_pampeana['anio'] = 2005\n",
    "EPH2025_pampeana['anio'] = 2025\n",
    "\n",
    "# Unimos pampeana de las dos años\n",
    "EPH_total = pd.concat([EPH2005_pampeana, EPH2025_pampeana], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc54949-67d6-4b28-99b3-1844088506fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b0530-bce9-419f-96b4-315cebbdfb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardamos las variables con las que nos quedamos en esta lista\n",
    "variables = [\n",
    "   \"codusu\",\"region\", \"ch04\", \"ch06\", \"ch07\", \"ch08\", \"nivel_ed\", \"estado\",\n",
    "    \"cat_inac\", \"ipcf\", \"ch09\", \"cat_ocup\",  \n",
    "    \"ch15\", \"itf\",  \"ch03\", \"p47t\", \"p21\", \"pp3e_tot\", \"pp3f_tot\"\n",
    "]\n",
    "\n",
    "EPH2005_filtrado = EPH2005[variables]\n",
    "\n",
    "EPH2025_filtrado = EPH2025[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea995865-c6cc-496d-ab72-e66138b85cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos el tipo de datos que hay en cada año\n",
    "print(EPH2005_filtrado.dtypes)\n",
    "print(EPH2025_filtrado.dtypes)\n",
    "\n",
    "#despues de esto vemos que mientras tenemos variables category en 2005, en 2025 están en int64 o float64, vamos a poner todo en un mismo formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d3ee44-e806-444a-9526-ac3968f65619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora, para arreglar y que tengan el mismo formato en ambas bases de dato, nos fijamos con la función .unique() en cada\n",
    "#variable para armar un diccionari para cada una variable y después cambiar su valor para que esten iguales\n",
    "mapping_ch04 = {\n",
    "    'Varón': 1,\n",
    "    'Mujer': 2\n",
    "}\n",
    "\n",
    "mapping_ch07 = {\n",
    "    'Unido': 1,\n",
    "    'Casado': 2,\n",
    "    'Separado o divorciado': 3,\n",
    "    'Viudo': 4,\n",
    "    'Soltero': 5,\n",
    "    'Ns./Nr.': pd.NA\n",
    "}\n",
    "mapping_ch08 = {\n",
    "    'Obra social (incluye PAMI)': 1,\n",
    "    'Mutual/Prepaga/Servicio de emergencia': 2,\n",
    "    'Planes y seguros públicos': 3,\n",
    "    'No paga ni le descuentan': 4,\n",
    "    'Ns./Nr.': pd.NA,\n",
    "    'Obra social y mutual/prepaga/servicio de emergencia': 12,\n",
    "    'Obra social y planes y seguros públicos': 13,\n",
    "    'Mutual/prepaga/servicio de emergencia/planes y seguros públicos': 23,\n",
    "    'Obra social, mutual/prepaga/servicio de emergencia y Planes y Seguros Públicos': 123\n",
    "}\n",
    "mapping_nivel_ed = {\n",
    "    'Primaria Incompleta (incluye educación especial)': 1,\n",
    "    'Primaria Completa': 2,\n",
    "    'Secundaria Incompleta': 3,\n",
    "    'Secundaria Completa': 4,\n",
    "    'Superior Universitaria Incompleta': 5,\n",
    "    'Superior Universitaria Completa': 6,\n",
    "    'Sin instrucción': 7,\n",
    "    'Ns./Nr.': pd.NA\n",
    "}\n",
    "mapping_estado = {\n",
    "    \"Entrevista individual no realizada (no respuesta al cuestion\": 0,\n",
    "    'Ocupado': 1,\n",
    "    'Desocupado': 2,\n",
    "    'Inactivo': 3,\n",
    "    'Menor de 10 años': 4\n",
    "}\n",
    "mapping_cat_inac = {\n",
    "    'Jubilado/pensionado': 1,\n",
    "    'Rentista': 2,\n",
    "    'Estudiante': 3,\n",
    "    'Ama de casa': 4,\n",
    "    'Menor de 6 años': 5,\n",
    "    'Discapacitado': 6,\n",
    "    'Otros': 7,\n",
    "    0.0: 0\n",
    "}\n",
    "mapping_ch15 = {\n",
    "    'En esta localidad': 1,\n",
    "    'En otra localidad': 2,\n",
    "    'En otra provincia (especificar)': 3,\n",
    "    'En un país limítrofe': 4,\n",
    "    'En otro país': 5,\n",
    "    'Ns./Nr.': pd.NA\n",
    "}\n",
    "mapping_ch09 = {\n",
    "    'Sí': 1,\n",
    "    'No': 2,\n",
    "    'Menor de 2 años': 3,\n",
    "    'Ns./Nr.': pd.NA\n",
    "}\n",
    "mapping_ch03 = {\n",
    "    'Jefe': 1,\n",
    "    'Cónyuge/Pareja': 2,\n",
    "    'Hijo/Hijastro': 3,\n",
    "    'Yerno/Nuera': 4,\n",
    "    'Nieto': 5,\n",
    "    'Madre/Padre': 6,\n",
    "    'Suegro': 7,\n",
    "    'Hermano': 8,\n",
    "    'Otros familiares': 9,\n",
    "    'No familiares': 10\n",
    "}\n",
    "mapping_cat_ocup = {\n",
    "    'Patrón': 1,\n",
    "    'Cuenta propia': 2,\n",
    "    'Obrero o empleado': 3,\n",
    "    'Trabajador familiar sin remuneración': 4,\n",
    "    0.0 : 0\n",
    "}\n",
    "\n",
    "def limpiar_edad(x):\n",
    "    if isinstance(x, str):\n",
    "        if 'Menos de 1' in x:\n",
    "            return 0\n",
    "        elif '98' in x:\n",
    "            return 99\n",
    "        else:\n",
    "            return pd.NA\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "EPH2005_filtrado.loc[:, 'ch04'] = EPH2005_filtrado['ch04'].map(mapping_ch04).astype('Int64')\n",
    "EPH2005_filtrado.loc[:, 'ch06'] = EPH2005_filtrado['ch06'].apply(limpiar_edad).astype('Int64')\n",
    "EPH2005_filtrado.loc[:, 'ch07'] = EPH2005_filtrado['ch07'].map(mapping_ch07).astype('Int64')\n",
    "EPH2005_filtrado.loc[:, 'ch08'] = EPH2005_filtrado['ch08'].map(mapping_ch08).astype('Int64')\n",
    "EPH2005_filtrado.loc[:, 'nivel_ed'] = EPH2005_filtrado['nivel_ed'].map(mapping_nivel_ed).astype('Int64')\n",
    "EPH2005_filtrado.loc[:, 'estado'] = EPH2005_filtrado['estado'].map(mapping_estado).astype('Int64')\n",
    "EPH2005_filtrado.loc[:, 'cat_inac'] = EPH2005_filtrado['cat_inac'].map(mapping_cat_inac).astype('Int64')\n",
    "EPH2005_filtrado.loc[:, 'ch15'] = EPH2005_filtrado['ch15'].map(mapping_ch15).astype('Int64')\n",
    "EPH2005_filtrado.loc[:, 'ch09'] = EPH2005_filtrado['ch09'].map(mapping_ch09).astype('Int64')\n",
    "EPH2005_filtrado.loc[:, 'ch03'] = EPH2005_filtrado['ch03'].map(mapping_ch03).astype('Int64')\n",
    "EPH2005_filtrado.loc[:, 'cat_ocup'] = EPH2005_filtrado['cat_ocup'].map(mapping_cat_ocup).astype('Int64')\n",
    "\n",
    "#Decidimos no considerar los 9 como Nan. Los consideramos una respuesta más.\n",
    "\n",
    "# Vemos cambios\n",
    "print(EPH2005_filtrado.head(10))\n",
    "print(EPH2005_filtrado.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5008cdc2-bdc6-408a-bfae-521a31262628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Columnas categóricas que ya son números significativos\n",
    "categ_numericas = [\"ch04\",\"ch03\",\"ch06\",\"ch07\",\"ch08\",\"ch09\",\"ch15\",\n",
    "                   \"nivel_ed\",\"estado\",\"cat_inac\",\"cat_ocup\"]\n",
    "\n",
    "# Columnas float\n",
    "float_cols = [\"ipcf\",\"itf\",\"p47t\",\"p21\"]\n",
    "\n",
    "# Convertimos categóricas a Int64\n",
    "for col in categ_numericas:\n",
    "    if col in EPH2005_filtrado.columns:\n",
    "        EPH2005_filtrado[col] = pd.to_numeric(EPH2005_filtrado[col], errors='coerce').astype('Int64')\n",
    "    if col in EPH2025_filtrado.columns:\n",
    "        EPH2025_filtrado[col] = pd.to_numeric(EPH2025_filtrado[col], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convertimos tambie´n a los floats\n",
    "for col in float_cols:\n",
    "    if col in EPH2005_filtrado.columns:\n",
    "        EPH2005_filtrado[col] = pd.to_numeric(EPH2005_filtrado[col], errors='coerce').astype(float)\n",
    "    if col in EPH2025_filtrado.columns:\n",
    "        EPH2025_filtrado[col] = pd.to_numeric(EPH2025_filtrado[col], errors='coerce').astype(float)\n",
    "\n",
    "# Revisamos tipos\n",
    "print(\"EPH2005 (Región Pampeana):\")\n",
    "print(EPH2005_filtrado.dtypes)\n",
    "print(\"\\nEPH2025 (Región Pampeana):\")\n",
    "print(EPH2025_filtrado.dtypes)\n",
    "\n",
    "#Ahora vemos que quedaron iguales en tipos de datos, menos región que vamos a \n",
    "#quedarnos solo con región pampeana antes de unir las bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f5711-d4aa-40ee-8b47-d339e6f6bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de unir las bases, vamos a chequear valores negativos \n",
    "\n",
    "# Definimos la lista exacta de variables que quieres revisar.\n",
    "variables_a_revisar = ['ipcf', 'ch15', 'itf', 'p47t', 'p21']\n",
    "\n",
    "print(\"--- Conteo de valores negativos en EPH 2005 ---\")\n",
    "# Filtramos el DataFrame para quedarnos solo con las filas donde cualquier\n",
    "# valor en las columnas especificadas es negativo, y luego contamos.\n",
    "negativos_2005 = EPH2005_filtrado[variables_a_revisar][EPH2005_filtrado[variables_a_revisar] < 0].count()\n",
    "print(negativos_2005)\n",
    "\n",
    "\n",
    "print(\"\\n--- Conteo de valores negativos en EPH 2025 ---\")\n",
    "# Repetimos el mismo proceso para la base de datos de 2025.\n",
    "negativos_2025 = EPH2025_filtrado[variables_a_revisar][EPH2025_filtrado[variables_a_revisar] < 0].count()\n",
    "print(negativos_2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a1356-13f1-41e0-9c16-f5e39b071856",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    \"codusu\", \"ch04\", \"ch06\", \"ch07\", \"ch08\", \"nivel_ed\", \"estado\",\n",
    "    \"cat_inac\", \"ipcf\", \"ch09\", \"cat_ocup\",\n",
    "    \"ch15\", \"itf\", \"ch03\", \"p47t\", \"p21\", \"pp3e_tot\", \"pp3f_tot\"\n",
    "]\n",
    "\n",
    "# Para 2005: solo filtramos por región Pampeana y seleccionamos las variables.\n",
    "# No se limpian negativos porque, como se ve en el codigo anterior, para el año 2005, no hay.\n",
    "EPH2005_pampeana = EPH2005_filtrado.loc[\n",
    "    EPH2005_filtrado['region'] == \"Pampeana\",\n",
    "    variables\n",
    "].copy()\n",
    "\n",
    "# Para 2025: aplicamos TODOS los filtros a la vez usando el operador '&' (y).\n",
    "# Condición 1: La región debe ser 43 (Pampeana).\n",
    "# Condición 2: El ingreso p47t debe ser mayor o igual a 0.\n",
    "# Condición 3: El ingreso p21 debe ser mayor o igual a 0.\n",
    "EPH2025_pampeana = EPH2025_filtrado.loc[\n",
    "    (EPH2025_filtrado['region'] == 43) &     \n",
    "    (EPH2025_filtrado['p47t'] >= 0) &   \n",
    "    (EPH2025_filtrado['p21'] >= 0),           \n",
    "    variables\n",
    "].copy()\n",
    "\n",
    "# Ahora sí, agregamos año y unimos\n",
    "EPH2005_pampeana['anio'] = 2005\n",
    "EPH2025_pampeana['anio'] = 2025\n",
    "\n",
    "EPH_total = pd.concat([EPH2005_pampeana, EPH2025_pampeana], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3aab7-f2a0-4a83-829e-edfdb1982e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPH_total.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee629fa-e2ba-469b-ac1c-2d12e3e27c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990a3dd-6924-417c-8438-bcb19ef3fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar cuántas personas respondieron estado respondieron == 0 por año\n",
    "respondieron_estado0 = EPH_total[EPH_total[\"estado\"] == 0].groupby(\"anio\").size()\n",
    "\n",
    "print(\"Cantidad de personas que no respondieron su condición de actividad por año:\")\n",
    "print(respondieron_estado0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a14784-bb2d-4c8f-b51f-44bdf92cf274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca lo que pasó fue que nos dimos cuenta que no aparecían los estado == 0 del 2025. Nos fijamos en donde exactamente habíamos perdido esos datos\n",
    "conteo_inicial_2025 = (EPH2025_filtrado['estado'] == 0).sum()\n",
    "\n",
    "#efectivamentem antes de unir las bases de datos habían 75 personas con estado == 0\n",
    "print(f\"En el DataFrame 'EPH2025_filtrado' original, hay {conteo_inicial_2025} filas con estado == 0.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a539e8-efdb-4d1d-914b-8db4f1a27df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para verificar, creamos un data frame con estas variables\n",
    "df_estado0_2025 = EPH2025_filtrado[EPH2025_filtrado['estado'] == 0]\n",
    "\n",
    "# De esas 75, ¿cuántas son pampeanas?\n",
    "filas_region_ok = (df_estado0_2025['region'] == 43).sum()\n",
    "#11 eran pampeanas\n",
    "\n",
    "# Prueba 2: ¿Cuántas de estas 75 filas tienen un ingreso p47t >= 0?\n",
    "filas_p47t_ok = (df_estado0_2025['p47t'] >= 0).sum()\n",
    "#NINGUNA tenía el p47t (monto total de ingreso individual percibido en el mes de referencia) <= 0\n",
    "#entonces cuando quitamos estos sujetos, los perdimos de nuestra pase de datos, pero eran 11 en definitiva\n",
    "\n",
    "# Prueba 3: ¿Cuántas de estas 75 filas tienen un ingreso p21 >= 0?\n",
    "filas_p21_ok = (df_estado0_2025['p21'] >= 0).sum()\n",
    "#Todas tenían p21 (monto de ingreso de la ocupación principal)>= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5fee96-5995-45f1-be9f-49fc32f7bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos itf > 0\n",
    "respondieron = EPH_total[EPH_total['itf'] > 0].copy()\n",
    "# Vemos itf = 0 (es decir, no respondieron)\n",
    "norespondieron = EPH_total[EPH_total['itf'] == 0].copy()\n",
    "print(\"Número de observaciones que respondieron ITF:\", respondieron.shape[0])\n",
    "print(\"Número de observaciones que no respondieron ITF:\", norespondieron.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be9ebca-969a-4e40-a03e-94dbceb45b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar respondieron por año\n",
    "respondieron_2005 = respondieron[respondieron['anio'] == 2005].copy()\n",
    "respondieron_2025 = respondieron[respondieron['anio'] == 2025].copy()\n",
    "\n",
    "# Separar norespondieron por año\n",
    "norespondieron_2005 = norespondieron[norespondieron['anio'] == 2005].copy()\n",
    "norespondieron_2025 = norespondieron[norespondieron['anio'] == 2025].copy()\n",
    "\n",
    "# Revisar dimensiones\n",
    "print(\"Respondieron 2005:\", respondieron_2005.shape)\n",
    "print(\"Respondieron 2025:\", respondieron_2025.shape)\n",
    "print(\"No respondieron 2005:\", norespondieron_2005.shape)\n",
    "print(\"No respondieron 2025:\", norespondieron_2025.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb7c05-082e-4768-bdec-e7ea855018c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c3a4b7-7e17-4e5b-baee-e16e751c8e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos la tabla, si no la encuentra nos dice que no se encontró (el try/except)\n",
    "try:\n",
    "    df_equiv = pd.read_excel(r\"C:\\Users\\Usuario\\Downloads\\tabla_adulto_equiv.xlsx\", skiprows=4, nrows=23)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'tabla_adulto_equiv.xlsx' no se encontró. Revisa la ruta.\")\n",
    "    # Si usas Jupyter o Google Colab, es mejor salir de la celda si hay error.\n",
    "    # Si es un script, podrías usar exit()\n",
    "    raise\n",
    "\n",
    "# Limpiamos y preparamos la tabla con las columnas que nos piden. Nos fijemos que todo tenga el formato correcto\n",
    "df_equiv.columns = ['edad_str', 'Mujeres', 'Varones']\n",
    "df_equiv_long = pd.melt(df_equiv, id_vars='edad_str', value_vars=['Mujeres', 'Varones'],\n",
    "                        var_name='sexo_str', value_name='adulto_equiv')\n",
    "df_equiv_long['ch04'] = df_equiv_long['sexo_str'].map({'Varones': 1, 'Mujeres': 2}).astype(int)\n",
    "df_equiv_long['ch06'] = df_equiv_long['edad_str'].str.extract('(\\d+)').astype(int)\n",
    "df_equiv_long.loc[df_equiv_long['edad_str'] == 'Menor de 1 año', 'ch06'] = 0\n",
    "df_equiv_final = df_equiv_long[['ch04', 'ch06', 'adulto_equiv']].dropna().sort_values(by=['ch04', 'ch06'])\n",
    "\n",
    "\n",
    "# Preparamos el data frame respondieorn\n",
    "# Creamos la base con ITF > 0 a partir de tu EPH_total\n",
    "# Esto filtra los hogares que no informaron ingresos.\n",
    "respondieron = EPH_total[EPH_total['itf'] > 0].copy()\n",
    "\n",
    "# Nos aseguramos de que no haya nulos en las columnas clave para el cálculo y de que tengan el tipo de dato correcto.\n",
    "columnas_clave = ['codusu', 'ch06', 'ch04', 'itf']\n",
    "respondieron = respondieron.dropna(subset=columnas_clave)\n",
    "respondieron['ch06'] = respondieron['ch06'].astype(int)\n",
    "respondieron['ch04'] = respondieron['ch04'].astype(int)\n",
    "\n",
    "\n",
    "# asignamos el adult equivs a cada persona\n",
    "# Función de búsqueda que encuentra el valor de adulto equivalente\n",
    "# para cada persona según su sexo y rango de edad.\n",
    "def obtener_adulto_equiv(fila, tabla_equivalencias):\n",
    "    sexo_persona = fila['ch04']\n",
    "    edad_persona = fila['ch06']\n",
    "    \n",
    "    # Filtramos la tabla de equivalencias por el sexo de la persona\n",
    "    tabla_sexo = tabla_equivalencias[tabla_equivalencias['ch04'] == sexo_persona]\n",
    "    \n",
    "    # Encuentra la fila correspondiente al rango de edad\n",
    "    # Se toma el último valor de edad que sea menor o igual a la edad de la persona\n",
    "    fila_equivalencia = tabla_sexo[tabla_sexo['ch06'] <= edad_persona]\n",
    "    \n",
    "    if not fila_equivalencia.empty:\n",
    "        return fila_equivalencia['adulto_equiv'].iloc[-1]\n",
    "    else:\n",
    "        # Si no lo encuentra (por ej. edad negativa), devuelve NaN\n",
    "        return np.nan\n",
    "\n",
    "# Aplicamos la función a cada fila del DataFrame\n",
    "respondieron['adulto_equiv'] = respondieron.apply(\n",
    "    obtener_adulto_equiv, \n",
    "    axis=1, \n",
    "    tabla_equivalencias=df_equiv_final\n",
    ")\n",
    "# Agrupamos hogar y ad_equiv\n",
    "# Usamos groupby con 'anio' y 'codusu' para identificar  cada hogar.\n",
    "# '.transform('sum')' calcula la suma de 'adulto_equiv' para cada grupo (hogar)\n",
    "# y luego asigna ese mismo valor total a cada miembro del hogar.\n",
    "\n",
    "print(\"\\nAgrupando por hogar y calculando 'ad_equiv_hogar'...\")\n",
    "respondieron['ad_equiv_hogar'] = respondieron.groupby(['anio', 'codusu'])['adulto_equiv'].transform('sum')\n",
    "print(\"¡Cálculo de 'ad_equiv_hogar' completado!\")\n",
    "\n",
    "\n",
    "#  Vemos los primeros 10 de la tabla, seleccionando columnas relevantes.\n",
    "# Deberías ver que las personas con el mismo 'codusu' y 'anio' tienen el mismo valor en 'ad_equiv_hogar'.\n",
    "print(respondieron[['anio', 'codusu', 'ch04', 'ch06', 'adulto_equiv', 'ad_equiv_hogar']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820bf9e4-dbe4-4ce0-9eeb-77a539c35b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219cff2-8654-493d-8f74-7c4175c79cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos valores de la CBT\n",
    "# Guardamos los valores de la canasta en variables para que el código sea más claro.\n",
    "cbt_2005 = 205.07\n",
    "cbt_2025 = 365177\n",
    "\n",
    "# Creamos columna ingreso necesario\n",
    "# Usamos np.where para aplicar un cálculo condicional basado en el año.\n",
    "print(\"Calculando el ingreso necesario para cada hogar...\")\n",
    "\n",
    "respondieron['ingreso_necesario'] = np.where(\n",
    "    respondieron['anio'] == 2005,                          \n",
    "    respondieron['ad_equiv_hogar'] * cbt_2005,               \n",
    "    respondieron['ad_equiv_hogar'] * cbt_2025                 \n",
    ")\n",
    "\n",
    "# Ejemplo para el año 2005\n",
    "print(respondieron[respondieron['anio'] == 2005][['anio', 'ad_equiv_hogar', 'ingreso_necesario']].head())\n",
    "\n",
    "# Ejemplo para el año 2025\n",
    "print(respondieron[respondieron['anio'] == 2025][['anio', 'ad_equiv_hogar', 'ingreso_necesario']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d610f-7253-40cc-845a-8c00578994b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fba8f4-7f62-41ff-bcbc-db85cb5b88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos columna pobe\n",
    "# Al igual que en el inciso anterior usamos np.wherepara crear una columna basandonos en una condición \n",
    "# Condición: si el ingreso del hogar ('itf') es menor que su 'ingreso_necesario'.\n",
    "# Valor si es verdadero: 1 (es pobre)\n",
    "# Valor si es falso: 0 (no es pobre)\n",
    "\n",
    "print(\"Creando la columna 'pobre'...\")\n",
    "respondieron['pobre'] = np.where(\n",
    "    respondieron['itf'] < respondieron['ingreso_necesario'], \n",
    "    1, \n",
    "    0\n",
    ")\n",
    "print(\"¡Columna 'pobre' creada!\")\n",
    "\n",
    "\n",
    "# Calculamos cantidad y porcentaje de pobres\n",
    "# Agrupamos el DataFrame por la columna 'anio'.\n",
    "# Usamos .agg() para realizar múltiples cálculos a la vez sobre la columna \"pobre\":\n",
    "#   - '\"sum\"nos da el total de pobres (porque suma todos los 1s).\n",
    "#   - \"count\" nos da el total de personas en la muestra para ese año.\n",
    "\n",
    "analisis_pobreza = respondieron.groupby('anio')['pobre'].agg(\n",
    "    Cantidad_Pobres='sum', \n",
    "    Total_Personas='count'\n",
    ")\n",
    "\n",
    "# Calculamos el porcentaje dividiendo la cantidad de pobres por el total y multiplicando por 100\n",
    "analisis_pobreza['Porcentaje_Pobreza'] = (analisis_pobreza['Cantidad_Pobres'] / analisis_pobreza['Total_Personas']) * 100\n",
    "\n",
    "\n",
    "# Resultados\n",
    "print(analisis_pobreza)\n",
    "print(\" Verificación de la columna 'pobre' (primeras 10 filas)\")\n",
    "print(respondieron[['anio', 'itf', 'ingreso_necesario', 'pobre']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da675dc1-a3fb-4ad5-b4d3-e098826f1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TP2 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eaf98d-2439-4ace-b4b6-da77d9fd6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARTE 1\n",
    "#EJERCICIO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe949d-35da-4b67-b0e6-c5aa7bcc7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamos los valores 0 y 1 de la columna 'pobre' a etiquetas de texto.\n",
    "respondieron['Condicion'] = respondieron['pobre'].map({0: 'No Pobre', 1: 'Pobre'})\n",
    "\n",
    "# Creamos la variable \"edad2\" (edad al cuadrado) con ch06\n",
    "respondieron['edad2'] = respondieron['ch06']**2\n",
    "\n",
    "# Gráficos\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Panel A: Histograma de la variable edad \n",
    "sns.histplot(data=respondieron, x='ch06', bins=30, ax=axes[0], color='#88708D', kde=True)\n",
    "axes[0].set_title('Panel A: Histograma de Edades (Región Pampeana)', fontsize=14)\n",
    "axes[0].set_xlabel('edad2', fontsize=12)\n",
    "axes[0].set_ylabel('Frecuencia', fontsize=12)\n",
    "\n",
    "# Panel B: Distribución de kernels para pobres y no pobres \n",
    "sns.kdeplot(data=respondieron, x='edad2', hue='Condicion', ax=axes[1], fill=True, \n",
    "            palette={'No Pobre': '#708D81', 'Pobre': '#F9B9B7'}) # Verde para No Pobre, Rojo/Rosa para Pobre\n",
    "axes[1].set_title('Panel B: Distribución de Edades por Condición de Pobreza', fontsize=14)\n",
    "axes[1].set_xlabel('edad2', fontsize=12)\n",
    "axes[1].set_ylabel('Densidad', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae0d842-178c-405f-802c-d7019153736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4f323-40ba-4d32-8853-b28f3bd77aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#con este diccionario, vamos a definir los distitnos grados de educación\n",
    "mapa_educ_anos = {\n",
    "    1: 4,   # Primaria Incompleta (promedio de años)\n",
    "    2: 7,   # Primaria Completa\n",
    "    3: 10,  # Secundaria Incompleta (7 prim + 3 sec)\n",
    "    4: 12,  # Secundaria Completa\n",
    "    5: 14,  # Superior Univ. Incompleta (12 sec + 2 univ)\n",
    "    6: 17,  # Superior Univ. Completa (12 sec + 5 carrera)\n",
    "    7: 0    # Sin instrucción\n",
    "}\n",
    "\n",
    "# Aplicamos el mapeo a la columna 'nivel_ed' para crear la nueva variable 'educ'\n",
    "# Usamos el DataFrame 'respondieron' que ya excluye los hogares sin respuesta de ingreso.\n",
    "respondieron['educ'] = respondieron['nivel_ed'].map(mapa_educ_anos)\n",
    "\n",
    "# Estadística descriptiva\n",
    "estadisticas_educ = respondieron['educ'].describe()[['mean', 'std', 'min', '50%', 'max']]\n",
    "\n",
    "print(\"-\"*65)\n",
    "print(\"--- Estadísticas Descriptivas para Años de Educación ('educ') ---\")\n",
    "print(estadisticas_educ)\n",
    "print(\"-\"*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a49fb-b8af-4042-bbcc-645655306ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6d5c2-3f2e-462c-ba42-4396d7bfc704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a ajustar precios 2005 a 2025\n",
    "#Factor de Inflación = IPC (1er Trimestre 2025) (365.18) / IPC (1er Trimestre 2005)(10.8)\n",
    "factor_inflacion = 33.81\n",
    "\n",
    "# Creamos la nueva columna 'itf_ajustado' en el DataFrame 'respondieron'\n",
    "respondieron['itf_ajustado'] = np.where(\n",
    "    respondieron['anio'] == 2005,\n",
    "    respondieron['itf'] * factor_inflacion,\n",
    "    respondieron['itf']\n",
    ")\n",
    "\n",
    "# Definimos la línea de pobreza de referencia del TP1\n",
    "linea_pobreza_2025 = 365177\n",
    "\n",
    "# Creamos la columna 'Condicion' para el gráfico del Panel B\n",
    "respondieron['Condicion'] = respondieron['pobre'].map({0: 'No Pobre', 1: 'Pobre'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08358e24-6e68-43c0-85ba-d0714e1a8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficos ahora\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Panel A: Histograma del Ingreso Total Familiar Ajustado\n",
    "sns.histplot(data=respondieron, x='itf_ajustado', bins=40, ax=axes[0], color='#302030', log_scale=True, kde=True)\n",
    "axes[0].axvline(x=linea_pobreza_2025, color='red', linestyle='--', linewidth=2, label=f'Línea de Pobreza (${linea_pobreza_2025:,.0f})')\n",
    "axes[0].set_title('Panel A: Histograma de Ingreso Total Familiar Ajustado', fontsize=14)\n",
    "axes[0].set_xlabel('Ingreso Total Familiar (ITF) - Escala Logarítmica', fontsize=12)\n",
    "axes[0].set_ylabel('Frecuencia', fontsize=12)\n",
    "axes[0].legend()\n",
    "\n",
    "# Panel B: Distribución de Kernels para Pobres y No Pobres \n",
    "sns.kdeplot(data=respondieron, x='itf_ajustado', hue='Condicion', ax=axes[1], fill=True, \n",
    "            log_scale=True, palette={'No Pobre': '#708D81', 'Pobre': '#F9B9B7'})\n",
    "axes[1].axvline(x=linea_pobreza_2025, color='red', linestyle='--', linewidth=2, label=f'Línea de Pobreza (${linea_pobreza_2025:,.0f})')\n",
    "axes[1].set_title('Panel B: Distribución de Ingresos por Condición de Pobreza', fontsize=14)\n",
    "axes[1].set_xlabel('Ingreso Total Familiar (ITF) - Escala Logarítmica', fontsize=12)\n",
    "axes[1].set_ylabel('Densidad', fontsize=12)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae300734-31f3-4e98-acb2-6611695b3476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199d5e3-9f25-4a04-99e4-fddbe598f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos solo los jefes de hogar (ch03 == 1)\n",
    "jefes_hogar = EPH_total[EPH_total['ch03'] == 1].copy()\n",
    "\n",
    "# Sumamos las horas trabajadas e imputamos a los NAS el valor 0\n",
    "jefes_hogar['horastrab'] = jefes_hogar['pp3e_tot'].fillna(0) + jefes_hogar['pp3f_tot'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23be299d-bfff-4d3d-a549-18c895b9aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos de nuevo solo los jefes de hogar (ch03 == 1)\n",
    "jefes_hogar = EPH_total[EPH_total['ch03'] == 1].copy()\n",
    "\n",
    "# Sumamos las horas trabajadas\n",
    "jefes_hogar['horastrab'] = jefes_hogar['pp3e_tot'].fillna(0) + jefes_hogar['pp3f_tot'].fillna(0)\n",
    "\n",
    "# Filtramos valores fuera de rango\n",
    "jefes_hogar = jefes_hogar[(jefes_hogar['horastrab'] >= 0) & (jefes_hogar['horastrab'] <= 200)]\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "estadisticas_horastrab = jefes_hogar['horastrab'].describe()\n",
    "#Tablita\n",
    "print(\"--- Estadísticas Descriptivas para Horas Trabajadas ('horastrab') ---\")\n",
    "print(f\"Promedio: {estadisticas_horastrab['mean']:.2f} horas\")\n",
    "print(f\"Desviación Estándar (sd): {estadisticas_horastrab['std']:.2f} horas\")\n",
    "print(f\"Mínimo (min): {estadisticas_horastrab['min']:.2f} horas\")\n",
    "print(f\"Percentil 50 (p50): {estadisticas_horastrab['50%']:.2f} horas\")\n",
    "print(f\"Máximo (max): {estadisticas_horastrab['max']:.2f} horas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53730a-3425-434c-94d9-42890a722f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed288266-9c91-4091-abbe-e881480fa54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 30)\n",
    "# Cantidad de observaciones\n",
    "# Usamos el DataFrame 'EPH_total', que es la base unificada final.\n",
    "obs_total = EPH_total.shape[0]\n",
    "obs_2005 = EPH_total[EPH_total['anio'] == 2005].shape[0]\n",
    "obs_2025 = EPH_total[EPH_total['anio'] == 2025].shape[0]\n",
    "print(\"Cantidad de observaciones 2005:\",obs_2005)\n",
    "print(\"Cantidad de observaciones 2025:\",obs_2025)\n",
    "print(\"Total\", obs_2005+obs_2025)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Cantidad de observaciones con NAs en la variable \"Pobre\"\n",
    "nas_total = norespondieron.shape[0]\n",
    "nas_2005 = norespondieron[norespondieron['anio'] == 2005].shape[0]\n",
    "nas_2025 = norespondieron[norespondieron['anio'] == 2025].shape[0]\n",
    "print(\"Cantidad de NAs 2005:\",nas_2005)\n",
    "print(\"Cantidad de NAs 2025:\",nas_2025)\n",
    "print(\"Total\", nas_2005+nas_2025)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Cantidad de Pobres \n",
    "# Usamos el DataFrame 'respondieron', que contiene la variable 'pobre'.\n",
    "# 'Pobre' == 1\n",
    "pobres_total = respondieron['pobre'].sum()\n",
    "pobres_2005 = respondieron[respondieron['anio'] == 2005]['pobre'].sum()\n",
    "pobres_2025 = respondieron[respondieron['anio'] == 2025]['pobre'].sum()\n",
    "print(\"Cantidad de pobres 2005:\",pobres_2005)\n",
    "print(\"Cantidad de pobres 2025:\", pobres_2025)\n",
    "print(\"Total\", pobres_2005+pobres_2025)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Cantidad de No Pobres \n",
    "# 'Pobre' == 0\n",
    "no_pobres_total = (respondieron['pobre'] == 0).sum()\n",
    "no_pobres_2005 = (respondieron[respondieron['anio'] == 2005]['pobre'] == 0).sum()\n",
    "no_pobres_2025 = (respondieron[respondieron['anio'] == 2025]['pobre'] == 0).sum()\n",
    "print(\"Cantidad de no pobres 2005:\",no_pobres_2005)\n",
    "print(\"Cantidad de no pobres 2025:\",no_pobres_2025)\n",
    "print(\"Total\", no_pobres_2005+no_pobres_2025)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Cantidad de variables limpias y homogeneizadas \n",
    "variables_total = EPH_total.shape[1]\n",
    "print(\"Variables total:\",variables_total)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92088b-abe5-4983-90c5-627221b8f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARTE 2. A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146942d5-9271-466d-9fb2-b633e56d900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 1\n",
    "# Calcular número de miembros en el hogar\n",
    "respondieron[\"ix_tot\"] = respondieron.groupby(\"codusu\")[\"codusu\"].transform(\"size\")\n",
    "\n",
    "# Revisar\n",
    "respondieron[[\"codusu\", \"ix_tot\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6879e4f3-d317-430b-8f06-ec40cafb1ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Factor de inflación 2005 → 2025\n",
    "factor_inflacion = 33.81\n",
    "respondieron['itf_ajustado'] = np.where(\n",
    "    respondieron['anio'] == 2005,\n",
    "    respondieron['itf'] * factor_inflacion,\n",
    "    respondieron['itf'])\n",
    "# Renombrar columnas para la matriz\n",
    "df_analisis = respondieron[['ch06', 'edad2', 'educ', 'itf_ajustado', 'horastrab', 'ix_tot']].copy()\n",
    "df_analisis.rename(columns={'ch06':'Edad', \n",
    "                            'edad2':'Edad²', \n",
    "                            'educ':'Educación', \n",
    "                            'itf_ajustado':'Ingreso Total Familiar', \n",
    "                            'horastrab':'Horas trabajadas', \n",
    "                            'ix_tot':'Miembros del hogar'}, inplace=True)\n",
    "# Matriz de correlaciones\n",
    "corr = df_analisis.corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', square=True,\n",
    "            xticklabels=corr.columns,\n",
    "            yticklabels=corr.columns)\n",
    "# Ajustes de etiquetas y título\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Matriz de Correlaciones de Variables de Análisis', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35576804-1798-4128-a03b-92ef5b190787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear un DataFrame base con los scores de los dos primeros componentes\n",
    "df_scores = pd.DataFrame(scores[:, :2], columns=['PC1', 'PC2'])\n",
    "\n",
    "# Añadir las columnas 'Condicion' y 'Año' del DataFrame 'respondieron'\n",
    "df_scores['Condicion'] = respondieron['Condicion'].values\n",
    "df_scores['Año'] = respondieron['anio'].values\n",
    "\n",
    "# Identificar y crear un nuevo DataFrame filtrado para excluir los outliers\n",
    "df_scores_filtrado = df_scores[df_scores['PC2'] < 8]\n",
    "\n",
    "# 2 filas, 1 columna. Ajustamos el tamaño para que sea más alto que ancho.\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 16), sharex=True) # sharex para ejes X comparables\n",
    "\n",
    "# Panel Superior: Gráfico para el año 2005\n",
    "sns.scatterplot(\n",
    "    ax=axes[0], \n",
    "    data=df_scores_filtrado[df_scores_filtrado['Año'] == 2005],\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    hue='Condicion', \n",
    "    palette={'No Pobre': '#708D81', 'Pobre': '#302030'},\n",
    "    alpha=0.7, \n",
    "    edgecolor='w', \n",
    "    s=60)\n",
    "\n",
    "axes[0].set_title('Distribución de Hogares en 2005', fontsize=16)\n",
    "axes[0].set_ylabel('Componente Principal 2 (Ciclo de Vida)')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend(title='Condición')\n",
    "\n",
    "# Limitamos el eje X del gráfico superior\n",
    "axes[0].set_xlim(left=df_scores_filtrado['PC1'].min(), right=4) \n",
    "\n",
    "# Panel Inferior: Gráfico para el año 2025\n",
    "sns.scatterplot(\n",
    "    ax=axes[1], \n",
    "    data=df_scores_filtrado[df_scores_filtrado['Año'] == 2025],\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    hue='Condicion', \n",
    "    palette={'No Pobre': '#A6D4C2', 'Pobre': '#F9B9B7'},\n",
    "    alpha=0.6, \n",
    "    edgecolor='w', \n",
    "    s=60)\n",
    "\n",
    "axes[1].set_title('Distribución de Hogares en 2025', fontsize=16)\n",
    "axes[1].set_xlabel('Componente Principal 1 (Índice Socioeconómico)')\n",
    "axes[1].set_ylabel('Componente Principal 2 (Ciclo de Vida)')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend(title='Condición')\n",
    "\n",
    "#  Título general y ajuste\n",
    "plt.suptitle('PCA: Comparación de la Distribución de Hogares entre 2005 y 2025 (Sin Outliers)', fontsize=20)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "print(f\"Nota: Se excluyeron {df_scores.shape[0] - df_scores_filtrado.shape[0]} hogares con características atípicas de ambos gráficos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e94be-b638-437e-925b-f9617cef7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 3\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Primero, creamos un DataFrame con los scores\n",
    "df_scores_densidad = pd.DataFrame(scores[:, :2], columns=['PC1', 'PC2'])\n",
    "\n",
    "# Ahora, filtramos los outliers para mejorar la visualización\n",
    "# Mantenemos solo los puntos donde el Componente 2 es menor a 8\n",
    "df_scores_densidad_filtrado = df_scores_densidad[df_scores_densidad['PC2'] < 8]\n",
    "\n",
    "# GRÁFICO MEJORADO: Densidad de Scores (filtrado) y Loadings\n",
    "# Extraemos los loadings para las flechas\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "scale_factor = 1.5 # Factor para que las flechas se vean mejor\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Graficamos la DENSIDAD usando el DataFrame FILTRADO\n",
    "sns.kdeplot(data=df_scores_densidad_filtrado, x='PC1', y='PC2', cmap=\"Blues\", fill=True, alpha=0.6)\n",
    "\n",
    "# Graficamos los loadings (flechas) encima, como antes\n",
    "for i in range(loadings.shape[0]):\n",
    "    plt.arrow(0, 0, loadings[i, 0] * scale_factor, loadings[i, 1] * scale_factor, \n",
    "              color='r', alpha=0.9, width=0.01, head_width=0.08)\n",
    "    plt.text(loadings[i, 0] * scale_factor * 1.15, loadings[i, 1] * scale_factor * 1.15, \n",
    "             df_analisis.columns[i], color='k', ha='center', va='center', fontsize=12,\n",
    "             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "plt.xlabel('Componente Principal 1 (Índice Socioeconómico)')\n",
    "plt.ylabel('Componente Principal 2 (Ciclo de Vida)')\n",
    "plt.title('PCA: Densidad de Scores y Loadings (Sin Outliers)', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.axhline(0, color='grey', lw=1)\n",
    "plt.axvline(0, color='grey', lw=1)\n",
    "plt.show()\n",
    "print(f\"Nota: Se excluyeron {len(scores) - len(df_scores_densidad_filtrado)} hogares con características atípicas para mejorar la visualización.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c6a43-1faa-4502-aba0-f56e745c2653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 3\n",
    "import seaborn as sns\n",
    "\n",
    "# Preparamos DataFrame con scores y la condición de pobreza\n",
    "df_scores_biplot = pd.DataFrame(scores[:, :2], columns=['PC1', 'PC2'])\n",
    "df_scores_biplot['Condicion'] = respondieron['Condicion'].values\n",
    "\n",
    "# Filtramos outliers para que el gráfico no se comprima\n",
    "df_scores_biplot_filtrado = df_scores_biplot[df_scores_biplot['PC2'] < 8]\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Grafico los scores coloreados por condición\n",
    "sns.scatterplot(data=df_scores_biplot_filtrado, x='PC1', y='PC2', hue='Condicion',\n",
    "                palette={'No Pobre': '#708D81', 'Pobre': '#F9B9B7'}, alpha=0.4)\n",
    "\n",
    "# Grafico los loadings (flechas) encima\n",
    "for i in range(loadings.shape[0]):\n",
    "    plt.arrow(0, 0, loadings[i, 0] * scale_factor, loadings[i, 1] * scale_factor, \n",
    "              color='black', alpha=0.8, width=0.01, head_width=0.08)\n",
    "    plt.text(loadings[i, 0] * scale_factor * 1.15, loadings[i, 1] * scale_factor * 1.15, \n",
    "             df_pca.columns[i], color='k', ha='center', va='center', fontsize=12,\n",
    "             bbox=dict(facecolor='white', alpha=0.7, edgecolor='k'))\n",
    "plt.xlabel('Componente Principal 1 (Índice Socioeconómico)')\n",
    "plt.ylabel('Componente Principal 2 (Ciclo de Vida)')\n",
    "plt.title('Biplot de PCA: Scores por Pobreza y Loadings', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.axhline(0, color='grey', lw=1)\n",
    "plt.axvline(0, color='grey', lw=1)\n",
    "plt.legend(title='Condición')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a348d6-24a3-4bab-9005-b70a2aa725d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 4\n",
    "# Varianza explicada\n",
    "var_explicada = pca.explained_variance_ratio_\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=[f'PC{i+1}' for i in range(len(var_explicada))], y=var_explicada*100, color='skyblue')\n",
    "plt.ylabel('Proporción de Varianza Explicada (%)')\n",
    "plt.xlabel('Componentes Principales')\n",
    "plt.title('Varianza Explicada por Cada Componente Principal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c5e93-bcbd-4d35-ab4f-47e687216f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARTE 2. B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c222d3e4-7e56-4cb4-a111-c081d1318a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 5 A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6fe9f-604d-49b3-be3b-c5ea4a319fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos librerías para hacer los clusters\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Definimos las variables de interés\n",
    "X = respondieron[[\"ch06\", \"itf_ajustado\"]]\n",
    "\n",
    "# Función para graficar resultados de clustering\n",
    "def plot_kmeans(X, k, n_init=20): \n",
    "    kmeans = KMeans(n_clusters=k, n_init=n_init, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    plt.figure(figsize=(6,5)) #Colores y dimensiones de los gráficos\n",
    "    plt.scatter(X.iloc[:,0], X.iloc[:,1], c=labels, cmap=\"coolwarm\", s=30, alpha=0.6) \n",
    "    plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], \n",
    "                c=\"red\", marker=\"X\", s=200, label=\"Centroides\")\n",
    "    plt.xlabel(\"Edad\") #Etiqueta eje X\n",
    "    plt.ylabel(\"Ingreso Total Familiar\") #Etiqueta eje Y\n",
    "    plt.title(f\"K-Means con k={k}\") #Título de nuestro gráfico\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Ejecutamos con k=2, k=4 y k=10\n",
    "etiqueta_k2 = plot_kmeans(X, k=2)\n",
    "etiqueta_k4 = plot_kmeans(X, k=4)\n",
    "etiqueta_k10 = plot_kmeans(X, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0ede8-cbac-4ded-b5c4-28c4b344af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 5 B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c01c0a-0a2e-4496-ade3-bf65e5f59d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como medida de desimilitud vamos a utilizar una Inercia\n",
    "#Importamos las librerias\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selecciónamos las variables de interés\n",
    "X = respondieron[[\"ch06\", \"itf_ajustado\"]].dropna()\n",
    "\n",
    "# Escalamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Calculamos la inercia para k=1 a k=10\n",
    "inertias = []\n",
    "ks = range(1, 11)\n",
    "\n",
    "#Le damos los parámetros a la figura\n",
    "for k in ks:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=20, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Graficamos el Elbow\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(ks, inertias, marker=\"o\")\n",
    "plt.xlabel(\"Número de clusters (k)\") #Etiqueta eje X\n",
    "plt.ylabel(\"Inercia (WCSS)\") #Etiqueta eje Y\n",
    "plt.title(\"Método del Elbow\") #Título del gráfico\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d6973-67df-4e56-95a9-10bed0175545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a3588-0252-4f53-8836-2ada26a00a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Elegimos el data frame\n",
    "for _cand in [\"jefes_hogar\", \"respondieron\", \"base\", \"df\"]:\n",
    "    if _cand in globals():\n",
    "        df = globals()[_cand].copy()\n",
    "        break\n",
    "else:\n",
    "    raise NameError(\"No encuentro un DataFrame (jefes_hogar / respondieron / base / df). Cargá uno en memoria.\")\n",
    "\n",
    "# Coercionar todo lo numérico posible\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == \"O\":\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n",
    "\n",
    "cols_lower = {c.lower(): c for c in df.columns}\n",
    "\n",
    "def find_by_substr(required_terms, avoid_terms=None):\n",
    "    \"\"\"\n",
    "    Busca una columna que contenga TODOS los substrings de required_terms.\n",
    "    Si avoid_terms se pasa, debe NO contener ninguno de esos substrings.\n",
    "    Devuelve el nombre real de la columna o None.\n",
    "    \"\"\"\n",
    "    req = [t.lower() for t in (required_terms if isinstance(required_terms, (list,tuple)) else [required_terms])]\n",
    "    avoid = [t.lower() for t in (avoid_terms if isinstance(avoid_terms, (list,tuple)) else ([] if avoid_terms is None else [avoid_terms]))]\n",
    "    for lc, real in cols_lower.items():\n",
    "        if all(t in lc for t in req) and all(t not in lc for t in avoid):\n",
    "            return real\n",
    "    return None\n",
    "\n",
    "def first_present(candidates):\n",
    "    \"\"\"Devuelve la primera columna existente (case-insensitive) en candidates, o None.\"\"\"\n",
    "    for cand in candidates:\n",
    "        if cand.lower() in cols_lower:\n",
    "            return cols_lower[cand.lower()]\n",
    "    return None\n",
    "\n",
    "used = {}    # para registrar qué columnas se usaron\n",
    "\n",
    "#Busca las variables edad y edad2 para utilizar\n",
    "edad_col = first_present([\"edad\",\"ch06\"])\n",
    "if edad_col is None:\n",
    "    # última chance: algo que contenga 'edad'\n",
    "    edad_col = find_by_substr([\"edad\"])\n",
    "if edad_col is None:\n",
    "    raise KeyError(\"No encontré columna de edad (pruebo con 'edad' o 'ch06').\")\n",
    "\n",
    "df[\"edad2\"] = pd.to_numeric(df[edad_col], errors=\"coerce\") ** 2\n",
    "used[\"edad\"] = edad_col\n",
    "used[\"edad2\"] = \"edad2\"\n",
    "\n",
    "#Busca la variable educación para utilizar\n",
    "educ_col = first_present([\"educ\",\"anios_educ\",\"años_educ\",\"anios_de_educacion\",\"ch14\"])\n",
    "if educ_col is None:\n",
    "    educ_col = find_by_substr([\"educ\"])\n",
    "if educ_col is None:\n",
    "    raise KeyError(\"No encontré columna de educación (p.ej. 'educ' o 'ch14').\")\n",
    "used[\"educ\"] = educ_col\n",
    "\n",
    "#Busca la variable Ingreso Total para utilizar\n",
    "itf_col = first_present([\"itf\",\"itf_ajustado\",\"ingreso_total_familiar\",\"ingreso_familiar\",\"ingreso_hogar\",\"ii_fami\"])\n",
    "if itf_col is None:\n",
    "    itf_col = find_by_substr([\"ingreso\",\"fami\"]) or find_by_substr([\"itf\"])\n",
    "if itf_col is None:\n",
    "    raise KeyError(\"No encontré ITF/ingreso familiar (p.ej. 'itf' o 'ingreso_total_familiar').\")\n",
    "used[\"itf\"] = itf_col\n",
    "\n",
    "#Busca la variable miembros del hogar para utilizar\n",
    "hh_col = first_present([\"miembros_hogar\",\"ix_tot\",\"ix_tot.\",\"ix_totales\",\"cant_miembros\",\"IX_TOT\",\"IX_Tot\"])\n",
    "if hh_col is None:\n",
    "    hh_col = find_by_substr([\"ix\",\"tot\"]) or find_by_substr([\"miembros\",\"hogar\"])\n",
    "if hh_col is None:\n",
    "    raise KeyError(\"No encontré 'miembros_hogar' / 'IX_TOT'.\")\n",
    "used[\"miembros_hogar\"] = hh_col\n",
    "\n",
    "#Busca la variable horas trabajadas para utilizar\n",
    "horas_col = first_present([\"horastrab\",\"horas_trab\",\"hs_trab\",\"horas\"])\n",
    "if horas_col is None:\n",
    "    #sumo PP3E_TOT + PP3F_TOT si existen\n",
    "    pp3e = first_present([\"PP3E_TOT\",\"pp3e_tot\",\"pp3e\"]) or find_by_substr([\"pp3e\"])\n",
    "    pp3f = first_present([\"PP3F_TOT\",\"pp3f_tot\",\"pp3f\"]) or find_by_substr([\"pp3f\"])\n",
    "    if (pp3e is not None) or (pp3f is not None):\n",
    "        df[\"horastrab\"] = df.get(pp3e, 0).fillna(0) + df.get(pp3f, 0).fillna(0)\n",
    "        horas_col = \"horastrab\"\n",
    "    else:\n",
    "        horas_col = find_by_substr([\"hora\",\"trab\"])\n",
    "        if horas_col is None:\n",
    "            #si no hay nada, creo NaN y sigo; luego dropna limpiará filas sin horas\n",
    "            df[\"horastrab\"] = np.nan\n",
    "            horas_col = \"horastrab\"\n",
    "\n",
    "used[\"horastrab\"] = horas_col\n",
    "\n",
    "# Armamos la matriz\n",
    "vars_target = [edad_col, \"edad2\", educ_col, itf_col, hh_col, horas_col]\n",
    "# Convertir a numérico y limpiar inf/na\n",
    "for c in vars_target:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "X = df[vars_target].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Si quedó vacío, reportar qué faltó\n",
    "if X.empty:\n",
    "    faltantes = {k:v for k,v in used.items() if v is None}\n",
    "    raise ValueError(f\"No quedaron filas después de dropna(). Revisá NAs/columnas. Mapeo usado: {used}\")\n",
    "\n",
    "#Estandarizamos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Realizamos un muestreo\n",
    "MAX_N = 8000  #Elegimos cuan grande queremos que sea la muestra\n",
    "if X_scaled.shape[0] > MAX_N:\n",
    "    sample_idx = np.random.RandomState(42).choice(X_scaled.shape[0], size=MAX_N, replace=False)\n",
    "    X_scaled_plot = X_scaled[sample_idx]\n",
    "    sample_note = f\" (muestreadas {MAX_N} de {X_scaled.shape[0]} obs)\"\n",
    "else:\n",
    "    X_scaled_plot = X_scaled\n",
    "    sample_note = \"\"\n",
    "\n",
    "#Realizamos el clustering jerárquico y dendrograma\n",
    "Z = linkage(X_scaled_plot, method=\"ward\")\n",
    "\n",
    "plt.figure(figsize=(12, 6)) #Parámetros de la figura\n",
    "dendrogram(Z, truncate_mode=\"level\", p=4, show_leaf_counts=True) #Nos da un punto de corte del dendograma y le agrega etiquetas\n",
    "plt.title(\"Dendrograma - Clustering Jerárquico (Ward)\" + sample_note) #Título del dendograma\n",
    "plt.xlabel(\"Clusters agregados\") #Título del eje x\n",
    "plt.ylabel(\"Distancia (varianza intra-cluster)\") #Titulo del eje y\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50abf5d-5201-469c-b1bd-26b8afdfffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c7faeb-7114-4428-a4d0-b2a0894d4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K=2\n",
    "#Importamos las librerías\n",
    "pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# Seleccionamos las variables continuas y categóricas que usaremos como predictores.\n",
    "variables_continuas = ['ch06', 'educ', 'ipcf', 'horastrab', 'miembros_hogar'] \n",
    "variables_categoricas = ['ch04', 'ch07', 'ch08', 'cat_ocup'] \n",
    "\n",
    "# Creamos el DataFrame de características. Usamos el dataframe 'respondieron' que ya fue limpiado. \n",
    "df_kmeans = respondieron[variables_continuas + variables_categoricas].dropna()\n",
    "\n",
    "# Creamos las variables \"dummy\" para las categóricas\n",
    "df_dummies = pd.get_dummies(df_kmeans, columns=variables_categoricas, drop_first=True)\n",
    "\n",
    "# Separamos las características (X) de la etiqueta real que queremos predecir (y)\n",
    "X = df_dummies\n",
    "y = respondieron.loc[df_kmeans.index]['pobre'] \n",
    "\n",
    "# Estandarizamos \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#Ejecutar el Algoritmo K-Means \n",
    "kmeans = KMeans(n_clusters=2, random_state=10, n_init='auto')\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# Obtenemos las etiquetas que K-Means asignó a cada cluster\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Realizamos el gráfico\n",
    "df_plot = respondieron.loc[X.index, ['ch06', 'itf']].copy()\n",
    "df_plot['Cluster'] = cluster_labels\n",
    "\n",
    "# Graficamos los resultados\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=df_plot, x='ch06', y='itf', hue='Cluster', palette='viridis', alpha=0.7, s=20)\n",
    "\n",
    "plt.title('K-Means (k=2) - Visualización Edad vs. ITF por Clúster', fontsize=16)\n",
    "plt.xlabel('Edad (ch06)', fontsize=12)\n",
    "plt.ylabel('Ingreso Total Familiar (ITF)', fontsize=12)\n",
    "plt.legend(title='Clúster Asignado')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a89c9-afd4-465c-9520-f95fc8664d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K=4\n",
    "#Seleccionamos las variables continuas y categóricas que usaremos como predictores\n",
    "variables_continuas = ['ch06', 'educ', 'ipcf', 'horastrab', 'miembros_hogar']\n",
    "variables_categoricas = ['ch04', 'ch07', 'ch08', 'cat_ocup'] \n",
    "\n",
    "# Creamos el DataFrame de características. Usamos el dataframe 'respondieron' que ya fue limpiado\n",
    "df_kmeans = respondieron[variables_continuas + variables_categoricas].dropna()\n",
    "\n",
    "# Creamos las variables \"dummy\" para las categóricas\n",
    "df_dummies = pd.get_dummies(df_kmeans, columns=variables_categoricas, drop_first=True)\n",
    "\n",
    "# Separamos las características (X) de la etiqueta real que queremos predecir (y)\n",
    "X = df_dummies\n",
    "y = respondieron.loc[df_kmeans.index]['pobre'] # La variable 'pobre' es nuestra \"verdad\" para comparar\n",
    "\n",
    "# Estandarizamos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Ejecutamos el Algoritmo K-Means\n",
    "kmeans = KMeans(n_clusters=4, random_state=10, n_init='auto')\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# Obtenemos las etiquetas que K-Means asignó a cada cluster\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "#Realizamos el gráfico\n",
    "df_plot = respondieron.loc[X.index, ['ch06', 'itf']].copy()\n",
    "df_plot['Cluster'] = cluster_labels\n",
    "\n",
    "# Graficamos los resultados\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=df_plot, x='ch06', y='itf', hue='Cluster', palette='viridis', alpha=0.7, s=20)\n",
    "\n",
    "plt.title('K-Means (k=4) - Visualización Edad vs. ITF por Clúster', fontsize=16) #Título del gráfico\n",
    "plt.xlabel('Edad (ch06)', fontsize=12) #Etiqueta eje X\n",
    "plt.ylabel('Ingreso Total Familiar (ITF)', fontsize=12) #Etiqueta eje Y\n",
    "plt.legend(title='Clúster Asignado')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01488fb6-eaa7-4c23-9456-9d70a05bc6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K=10\n",
    "#Seleccionamos las variables continuas y categóricas que usaremos como predictores\n",
    "variables_continuas = ['ch06', 'educ', 'ipcf', 'horastrab', 'miembros_hogar']\n",
    "variables_categoricas = ['ch04', 'ch07', 'ch08', 'cat_ocup'] \n",
    "\n",
    "# Creamos el DataFrame de características. Usamos el dataframe 'respondieron' que ya fue limpiado\n",
    "df_kmeans = respondieron[variables_continuas + variables_categoricas].dropna()\n",
    "\n",
    "# Creamos las variables \"dummy\" para las categóricas.\n",
    "df_dummies = pd.get_dummies(df_kmeans, columns=variables_categoricas, drop_first=True)\n",
    "\n",
    "# Separamos las características (X) de la etiqueta real que queremos predecir (y)\n",
    "X = df_dummies\n",
    "y = respondieron.loc[df_kmeans.index]['pobre'] # La variable 'pobre' es nuestra \"verdad\" para comparar\n",
    "\n",
    "# Estandarizamos.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#Ejecutamos el Algoritmo K-Means\n",
    "kmeans = KMeans(n_clusters=10, random_state=10, n_init='auto')\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# Obtenemos las etiquetas que K-Means asignó a cada cluster\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Visualización del gráfico\n",
    "df_plot = respondieron.loc[X.index, ['ch06','itf']].copy()\n",
    "df_plot['Cluster'] = cluster_labels.astype(str)  # tratar como categórico\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Graficamos los resultados\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(\n",
    "    data=df_plot,\n",
    "    x='ch06', y='itf',\n",
    "    hue='Cluster',\n",
    "    hue_order=sorted(df_plot['Cluster'].unique(), key=int),\n",
    "    palette=sns.color_palette('tab10', n_colors=10), #Colores\n",
    "    alpha=0.7, s=20, legend='full'\n",
    ")\n",
    "plt.title('K-Means (k=10) - Edad vs. ITF por Clúster') #Título del gráfico\n",
    "plt.xlabel('Edad (ch06)'); plt.ylabel('Ingreso Total Familiar (ITF)') #Etiqueta eje X\n",
    "plt.legend(title='Clúster', ncol=2, bbox_to_anchor=(1.02, 1), loc='upper left') #Etiqueta eje Y\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c173ec3e-1df4-41db-a1bd-4b4700eebf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACA "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
